changeBg:N（主角相关工作地点）/N9.jpg -next
changeFigure:mygo_avemujica_v6/sakiko/341_casual-2023_rip/model.json  -animationFlag=on -motion=bye02 -expression=smile01 -next 
客服小祥:各位B站的朋友大家好。 -center
正如大家看到的一样，刚刚我所有的发言都是根据玩家的输入，用大语言模型实时生成的。 -center
大家估计没玩过自由度这么高的gal，也没用过演出效果这么好的LLM Chatbot吧（笑）
就好像真的在和客服小祥对话一样，是不是很有意思呢？ -center
那么这种神奇的效果是怎么实现的呢，接下来就要给大家揭秘了。 -center

给没有用过WebGAL的朋友解释一下：WebGAL游戏的运行逻辑是由一系列场景文件控制的。
所有文字、立绘、动画效果，以及分支跳转，都是由场景文件中写好的的脚本控制。
自然，从一个场景文件也可以跳转到另一个场景文件，这样能方便把多个章节分开，方便管理。

不过大家可能不知道的是，跳转的目标不仅可以是本地的另一个场景文件，也可以是一个链接，表示一个远程的资源或场景文件。

源码里对绝对链接甚至有特殊处理。

同时，这版WebGAL刚好提供了一个获取用户输入的功能，就像这样弹一个输入框 -next
getUserInput:a
客服小祥:然后，就可以把输入嵌入到链接里，发送给我们提前架好的服务器，请求新的场景脚本。
然后服务器拿到嵌入在链接中的输入，和大模型对话后，动态生成包含回复和下一次请求的脚本返回，如此就实现了双向的通信。

原理就是这样，接下来就可以进入实施阶段了。

首先需要一个和大模型通信的后端服务器。

我刚好正在练手写一个LLM桌宠插件，最近后端刚写出个能用的版本，前端还没开始写。
溜二创的时候忽然想到，WebGAL不就是一个巨大的前端吗，一读源码发现居然可以主动触发远程请求。

这下前后端分离架构了（笑）。

接下来需要写提示词，也就是需要让大模型理解丰川祥子复杂的人设。
这方面我确实也是没什么经验，虽然看起来我想把很多设定一股脑塞进去，但LLM的记忆力显然是有限的。
测试的时候，经常感觉不到【丰川祥子】的特点，而是真的在和一个普通的【客服】对话。


然后需要一个把大模型输出转换为场景脚本的简单程序。
其实比听上去更难，因为一个合格的二创除了文字以外还需要有优秀的演出效果，简单来说就是各种表情、动作、动画效果。
作为一个动态生成内容的项目，手动去调整各种参数显然并不现实。
然而我们是个AI项目，至少可以问问大模型它自己的返回的情感倾向是什么，然后在预设好的几类情感的演出中随机抽取一个就好了。
其实效果已经比我预期的要好了，如果愿意再微调应该能更惊艳。


最后，为了让有能力的网友们玩上这个项目，我会把当前版本的代码开源，你应该可以在简介或评论区找到github链接。
大模型的API KEY恕不提供，请大家自备。
顺便一提，我用的并非OpenAI或者Anthropic，而是某个国内的大模型。 -center
为避免打广告，视频里就不提它的名字了，不过其实代码仓库里能找到。 -center
不过因为程序里调的是OpenAI标准库，理论上也可以直接用ChatGPT系列模型，如果你有OpenAI API Key的话？

另外，WebGAL的源码我也进行了一点点魔改，主要是去除了针对http资源的预加载功能，以及把输入框的样式改了改。
更多细节请见仓库readme.md。

end